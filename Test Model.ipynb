{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Test\n",
    "\n",
    "This is the test notebook for the JPL-Code-Sample and it will generate both `results.csv` and `output`.\n",
    "\n",
    "## Generated Content\n",
    "\n",
    "`results.csv` contains the the percentages for each class type.\n",
    "\n",
    "`output` is the directory that contains all the image visualizations.\n",
    "\n",
    "## Results\n",
    "\n",
    "The `results.csv` is formatted as such: Each row is an image which has the corresponding filename.  The percentages for each class is in contained in the same column with its respective class name.\n",
    "\n",
    "## Image Visualizations\n",
    "\n",
    "There are three generated images in the output folder for each original testing image.\n",
    "\n",
    "1. Original Image (no prefix) (left)\n",
    "2. Class Label Colors (mask prefix) (middle)\n",
    "3. Transparent label mask (overlay prefix) (right)\n",
    "\n",
    "\n",
    "<img src=\"samples/original.jpeg\" style=\"width: 200px;\" align=\"left\">\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"samples/mask.jpeg\" style=\"width: 200px;\" align=\"left\">\n",
    "\n",
    "\n",
    "<img src=\"samples/overlay.jpeg\" style=\"width: 200px;\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from scipy import ndimage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of training image files.\n",
    "image_size = (512,512)\n",
    "\n",
    "# The test image path\n",
    "TEST_PATH = \"data/test/\"\n",
    "\n",
    "# The output path for visualizations.\n",
    "OUTPUT_PATH = \"output\"\n",
    "\n",
    "# The number of slices each image will be cut into.\n",
    "n_slices = 32\n",
    "\n",
    "# The ratio of the image.\n",
    "ratio = (1, 1)\n",
    "\n",
    "# The opacity of the class label color mask.\n",
    "mask_opacity = 0.3\n",
    "\n",
    "classes = ['vegetation', 'water', 'desert', 'clouds']\n",
    "\n",
    "# The path to save the model.\n",
    "MODEL_PATH = \"models\"\n",
    "\n",
    "# The name the model will be saved to.\n",
    "model_name = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open(os.path.join(MODEL_PATH, model_name + \".json\"), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(os.path.join(MODEL_PATH, model_name + \".h5\"))\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test images...\n",
      "Preparing test data.\n"
     ]
    }
   ],
   "source": [
    "# Read the URL for test data.\n",
    "with open(\"test_images.txt\", 'r') as f:\n",
    "    image_urls = f.read().split(\"\\n\")\n",
    "\n",
    "print(\"Downloading test images...\")    \n",
    "\n",
    "# Download the test images.\n",
    "for i, image_url in enumerate(image_urls):\n",
    "    utils.download_image(image_url, os.path.join(TEST_PATH, '_'.join(image_url.split('/')[8:])))\n",
    "    \n",
    "print(\"Preparing test data.\")\n",
    "\n",
    "# Prepare the test data.\n",
    "X_test = []\n",
    "full_images = []\n",
    "test_image_f_names = os.listdir(TEST_PATH)\n",
    "\n",
    "# Load all files.\n",
    "for f_name in test_image_f_names:\n",
    "    img = cv2.imread(os.path.join(TEST_PATH, f_name))    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resize = cv2.resize(img, image_size)\n",
    "    \n",
    "    # Preprocess test data.\n",
    "    slices = utils.prepare_images(img_resize, image_size, ratio, n_slices)\n",
    "    X_test.append(slices)\n",
    "    full_images.append(img_resize)\n",
    "    \n",
    "# Collect and format all test data.\n",
    "full_images = np.stack(full_images)\n",
    "X_test = np.stack(X_test)\n",
    "X_test = X_test.reshape(X_test.shape[0] * X_test.shape[1], X_test.shape[2], X_test.shape[3], X_test.shape[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57280/57344 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Predict class labels for slices.\n",
    "preds = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum probability of the model is the class label.\n",
    "labels = np.argmax(preds, axis=1)\n",
    "\n",
    "# Reshape the labels for results and visualization purposes.\n",
    "labels = np.reshape(labels, (len(full_images), n_slices, n_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize list to hold label percentages\n",
    "percentages = []\n",
    "\n",
    "for l in labels:\n",
    "    percentages.append(np.bincount(l.flatten()) / l.size)\n",
    "    \n",
    "# Collect percentages into dataframe and save to disk.\n",
    "results = pd.DataFrame(percentages, columns=classes)\n",
    "results['f_name'] = test_image_f_names\n",
    "results = results.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign color for each class.\n",
    "\n",
    "# Vegetation: Green\n",
    "# Water: Blue\n",
    "# Desert: Brown\n",
    "# Clouds: White\n",
    "\n",
    "colors = {\n",
    "    0:(124,252,0),\n",
    "    1:(244,164,96),\n",
    "    2:(0,191,255),\n",
    "    3:(255, 255, 255)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all test data and create visualizations.\n",
    "for i, (f_name, img, l) in enumerate(zip(test_image_f_names, full_images, labels)):\n",
    "    \n",
    "    # Initialize the class assignment mask.\n",
    "    assignment_mask = np.zeros((l.shape[0], l.shape[1], 3))\n",
    "    \n",
    "    # Fill class labels into assignment mask.\n",
    "    for label in xrange(len(classes)):\n",
    "        assignment_mask[np.isin(l, label)] = colors[label]\n",
    "    \n",
    "    # Convert image to BGR to see correct color channels in visualization.\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # assignment mask needs to be of type uint8 to lay mask over image.\n",
    "    assignment_mask = assignment_mask.astype('uint8')\n",
    "    \n",
    "    # Flip and rotate assignment mask to account for offset.\n",
    "    assignment_mask = cv2.resize(assignment_mask, image_size, interpolation=cv2.INTER_CUBIC)\n",
    "    assignment_mask = cv2.flip(ndimage.rotate(assignment_mask, 90),0)\n",
    "    \n",
    "    # Apply mask to image.\n",
    "    overlay = assignment_mask\n",
    "    overlay = cv2.addWeighted(overlay, mask_opacity, overlay, 1 - mask_opacity,\n",
    "                    0, overlay)\n",
    "    \n",
    "    # Save images to disk.\n",
    "    cv2.imwrite(os.path.join(OUTPUT_PATH, f_name), img)\n",
    "    cv2.imwrite(os.path.join(OUTPUT_PATH, \"overlay_\" + f_name), overlay)\n",
    "    cv2.imwrite(os.path.join(OUTPUT_PATH, \"mask_\" + f_name), assignment_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
