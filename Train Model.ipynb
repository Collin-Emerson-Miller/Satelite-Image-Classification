{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import urllib\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "from scipy import ndimage \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, MaxPool2D, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "The approach taken here is to slice a whole image into smaller equal slices and classify each slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of training image files.\n",
    "image_size = (512,512)\n",
    "\n",
    "# The number of slices each image will be cut into.\n",
    "n_slices = 32\n",
    "\n",
    "# The ratio of the image.\n",
    "ratio = (1, 1)\n",
    "\n",
    "# How many times to train on the entire dataset.\n",
    "n_epochs = 1\n",
    "\n",
    "# How many training images to send through the model at once.\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The training image corpus path.\n",
    "CORPUS_PATH = \"data/train\"\n",
    "\n",
    "# The test image path.\n",
    "TEST_PATH = \"data/test\"\n",
    "\n",
    "# The output path for visualizations.\n",
    "OUTPUT_PATH = \"output\"\n",
    "\n",
    "# The path to save the model.\n",
    "MODEL_PATH = \"models\"\n",
    "\n",
    "# The name the model will be saved to.\n",
    "model_name = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of classes from the corpus path.\n",
    "classes = os.listdir(CORPUS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all images in corpus path and collect the in a list, labeling them along the way.\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "label_mapping = {}\n",
    "\n",
    "for label, c in enumerate(classes):\n",
    "    terrain_path = os.path.join(CORPUS_PATH, c)\n",
    "    label_mapping[label] = c\n",
    "    for f_name in os.listdir(terrain_path):\n",
    "        \n",
    "        # Read and preprocess image.\n",
    "        img = cv2.imread(os.path.join(terrain_path, f_name))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_resize = cv2.resize(img, image_size)\n",
    "        \n",
    "        # Slice image into chunks.\n",
    "        slices = utils.prepare_images(img_resize, image_size, ratio, n_slices)\n",
    "        \n",
    "        # Append the images and labels to a the lists. \n",
    "        image_list.append(slices)\n",
    "        label_list.append(np.full((slices.shape[0]), label))\n",
    "        \n",
    "# Collect images and labels into numpy arrays.\n",
    "X_train = np.concatenate(image_list)\n",
    "labels = np.concatenate(label_list)\n",
    "\n",
    "# One hot encode labels for training.\n",
    "y_train = to_categorical(labels, num_classes=len(classes))\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[15, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Augment input shape if training is grayscale. \n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 5, input_shape=input_shape, padding='same',\n",
    "                             activation='elu', dilation_rate=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, 3, padding='same',\n",
    "                             activation='elu', dilation_rate=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, 3, padding='same',\n",
    "                             activation='elu', dilation_rate=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, 3, padding='same',\n",
    "                             activation='elu', dilation_rate=4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, 3, padding='same',\n",
    "                             activation='elu', dilation_rate=8))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, 3, padding='same',\n",
    "                             activation='elu', dilation_rate=16))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, 3, padding='same',\n",
    "                             activation='elu', dilation_rate=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "opt = optimizers.adam(lr=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(MODEL_PATH, model_name + \".json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(os.path.join(MODEL_PATH, model_name + \".h5\"))\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
